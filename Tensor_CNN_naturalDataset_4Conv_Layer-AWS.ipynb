{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "(256, 256, 3)\n",
      "car\n",
      "(100, 100, 3)\n",
      "cat\n",
      "(142, 161, 3)\n",
      "dog\n",
      "(389, 243, 3)\n",
      "airplane\n",
      "(112, 324, 3)\n",
      "motorbike\n",
      "(120, 195, 3)\n",
      "fruit\n",
      "(100, 100, 3)\n",
      "flower\n",
      "(468, 493, 3)\n"
     ]
    }
   ],
   "source": [
    "# Display the dimensions of the images\n",
    "from matplotlib.image import imread\n",
    "i = \"150\"\n",
    "img = imread('natural_images_v2/z_person/person_0'+ i +'.jpg')\n",
    "print(\"person\")\n",
    "print(img.shape)\n",
    "img = imread('natural_images_v2/z_car/car_0'+ i +'.jpg')\n",
    "print(\"car\")\n",
    "print(img.shape)\n",
    "img = imread('natural_images_v2/z_cat/cat_0'+ i +'.jpg')\n",
    "print(\"cat\")\n",
    "print(img.shape)\n",
    "img = imread('natural_images_v2/z_dog/dog_0'+ i +'.jpg')\n",
    "print(\"dog\")\n",
    "print(img.shape)\n",
    "img = imread('natural_images_v2/z_airplane/airplane_0'+ i +'.jpg')\n",
    "print(\"airplane\")\n",
    "print(img.shape)\n",
    "img = imread('natural_images_v2/z_motorbike/motorbike_0'+ i +'.jpg')\n",
    "print(\"motorbike\")\n",
    "print(img.shape)\n",
    "img = imread('natural_images_v2/z_fruit/fruit_0'+ i +'.jpg')\n",
    "print(\"fruit\")\n",
    "print(img.shape)\n",
    "img = imread('natural_images_v2/z_flower/flower_0'+ i +'.jpg')\n",
    "print(\"flower\")\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to resize and show a image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = Image.open(\"natural_images/z_person/person_0150.jpg\")\n",
    "my_image = np.array(image.resize((100, 100), Image.ANTIALIAS))\n",
    "print(my_image.shape)\n",
    "plt.imshow(my_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 150, 150, 3)\n",
      "(120, 1)\n",
      "(240, 150, 150, 3)\n",
      "(240, 1)\n",
      "(360, 150, 150, 3)\n",
      "(360, 1)\n",
      "(480, 150, 150, 3)\n",
      "(480, 1)\n",
      "(600, 150, 150, 3)\n",
      "(600, 1)\n",
      "(720, 150, 150, 3)\n",
      "(720, 1)\n",
      "(840, 150, 150, 3)\n",
      "(840, 1)\n",
      "(960, 150, 150, 3)\n",
      "(960, 1)\n",
      "(960, 8)\n"
     ]
    }
   ],
   "source": [
    "# Preparing Train data\n",
    "# CNN for car = 0, person = 1, dog = 2, airplane = 3 - 600 examples each for training\n",
    "# cat = 4, flower = 5, motorbike = 6, fruit = 7\n",
    "# training_x = (example,d,d,d), training_y = (example,d) -- > ofter one-hot encoding\n",
    "train_example = 121 # train_set size\n",
    "# Car ------------------------\n",
    "for i in range(1, train_example):\n",
    "    if(i <= 999 & i > 99):\n",
    "        image_address = \"natural_images/z_car/car_0\" + str(i) + \".jpg\"\n",
    "    if(i <= 99 & i > 9):\n",
    "        image_address = \"natural_images/z_car/car_00\" + str(i) + \".jpg\"\n",
    "    if(i <= 9 & i > 0):\n",
    "        image_address = \"natural_images/z_car/car_000\" + str(i) + \".jpg\"\n",
    "    image = Image.open(image_address)\n",
    "    my_image = np.array(image.resize((150, 150), Image.ANTIALIAS))\n",
    "    my_image = my_image.reshape(1,150,150,3)\n",
    "    if(i == 1):\n",
    "        train_x = my_image\n",
    "        train_y = np.array([0]).reshape(1,1)\n",
    "    else:\n",
    "        train_x = np.append(train_x, my_image, axis = 0)\n",
    "        temp = np.array([0]).reshape(1,1)\n",
    "        train_y = np.append(train_y, temp, axis = 0)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "# Person ----------------------\n",
    "for i in range(1, train_example):\n",
    "    if(i <= 999 & i > 99):\n",
    "        image_address = \"natural_images/z_person/person_0\" + str(i) + \".jpg\"\n",
    "    if(i <= 99 & i > 9):\n",
    "        image_address = \"natural_images/z_person/person_00\" + str(i) + \".jpg\"\n",
    "    if(i <= 9 & i > 0):\n",
    "        image_address = \"natural_images/z_person/person_000\" + str(i) + \".jpg\"\n",
    "    image = Image.open(image_address)\n",
    "    my_image = np.array(image.resize((150, 150), Image.ANTIALIAS))\n",
    "    my_image = my_image.reshape(1,150,150,3)\n",
    "\n",
    "    train_x = np.append(train_x, my_image, axis = 0)\n",
    "    temp = np.array([1]).reshape(1,1)\n",
    "    train_y = np.append(train_y, temp, axis = 0)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "# dog --------------------------\n",
    "for i in range(1, train_example):\n",
    "    if(i <= 999 & i > 99):\n",
    "        image_address = \"natural_images/z_dog/dog_0\" + str(i) + \".jpg\"\n",
    "    if(i <= 99 & i > 9):\n",
    "        image_address = \"natural_images/z_dog/dog_00\" + str(i) + \".jpg\"\n",
    "    if(i <= 9 & i > 0):\n",
    "        image_address = \"natural_images/z_dog/dog_000\" + str(i) + \".jpg\"\n",
    "    image = Image.open(image_address)\n",
    "    my_image = np.array(image.resize((150, 150), Image.ANTIALIAS))\n",
    "    my_image = my_image.reshape(1,150,150,3)\n",
    "    \n",
    "    train_x = np.append(train_x, my_image, axis = 0)\n",
    "    temp = np.array([2]).reshape(1,1)\n",
    "    train_y = np.append(train_y, temp, axis = 0)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "# airplane ----------------------\n",
    "for i in range(1, train_example):\n",
    "    if(i <= 999 & i > 99):\n",
    "        image_address = \"natural_images/z_airplane/airplane_0\" + str(i) + \".jpg\"\n",
    "    if(i <= 99 & i > 9):\n",
    "        image_address = \"natural_images/z_airplane/airplane_00\" + str(i) + \".jpg\"\n",
    "    if(i <= 9 & i > 0):\n",
    "        image_address = \"natural_images/z_airplane/airplane_000\" + str(i) + \".jpg\"\n",
    "    image = Image.open(image_address)\n",
    "    my_image = np.array(image.resize((150, 150), Image.ANTIALIAS))\n",
    "    my_image = my_image.reshape(1,150,150,3)\n",
    "    train_x = np.append(train_x, my_image, axis = 0)\n",
    "    temp = np.array([3]).reshape(1,1)\n",
    "    train_y = np.append(train_y, temp, axis = 0)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "# cat --------------------------\n",
    "for i in range(1, train_example):\n",
    "    if(i <= 999 & i > 99):\n",
    "        image_address = \"natural_images/z_cat/cat_0\" + str(i) + \".jpg\"\n",
    "    if(i <= 99 & i > 9):\n",
    "        image_address = \"natural_images/z_cat/cat_00\" + str(i) + \".jpg\"\n",
    "    if(i <= 9 & i > 0):\n",
    "        image_address = \"natural_images/z_cat/cat_000\" + str(i) + \".jpg\"\n",
    "    image = Image.open(image_address)\n",
    "    my_image = np.array(image.resize((150, 150), Image.ANTIALIAS))\n",
    "    my_image = my_image.reshape(1,150,150,3)\n",
    "    train_x = np.append(train_x, my_image, axis = 0)\n",
    "    temp = np.array([4]).reshape(1,1)\n",
    "    train_y = np.append(train_y, temp, axis = 0)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "# flower ------------------------\n",
    "for i in range(1, train_example):\n",
    "    if(i <= 999 & i > 99):\n",
    "        image_address = \"natural_images/z_flower/flower_0\" + str(i) + \".jpg\"\n",
    "    if(i <= 99 & i > 9):\n",
    "        image_address = \"natural_images/z_flower/flower_00\" + str(i) + \".jpg\"\n",
    "    if(i <= 9 & i > 0):\n",
    "        image_address = \"natural_images/z_flower/flower_000\" + str(i) + \".jpg\"\n",
    "    image = Image.open(image_address)\n",
    "    my_image = np.array(image.resize((150, 150), Image.ANTIALIAS))\n",
    "    my_image = my_image.reshape(1,150,150,3)\n",
    "    train_x = np.append(train_x, my_image, axis = 0)\n",
    "    temp = np.array([5]).reshape(1,1)\n",
    "    train_y = np.append(train_y, temp, axis = 0)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "# motorbike ----------------------\n",
    "for i in range(1, train_example):\n",
    "    if(i <= 999 & i > 99):\n",
    "        image_address = \"natural_images/z_motorbike/motorbike_0\" + str(i) + \".jpg\"\n",
    "    if(i <= 99 & i > 9):\n",
    "        image_address = \"natural_images/z_motorbike/motorbike_00\" + str(i) + \".jpg\"\n",
    "    if(i <= 9 & i > 0):\n",
    "        image_address = \"natural_images/z_motorbike/motorbike_000\" + str(i) + \".jpg\"\n",
    "    image = Image.open(image_address)\n",
    "    my_image = np.array(image.resize((150, 150), Image.ANTIALIAS))\n",
    "    my_image = my_image.reshape(1,150,150,3)\n",
    "    train_x = np.append(train_x, my_image, axis = 0)\n",
    "    temp = np.array([6]).reshape(1,1)\n",
    "    train_y = np.append(train_y, temp, axis = 0)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "# fruit -------------------------\n",
    "for i in range(1, train_example):\n",
    "    if(i <= 999 & i > 99):\n",
    "        image_address = \"natural_images/z_fruit/fruit_0\" + str(i) + \".jpg\"\n",
    "    if(i <= 99 & i > 9):\n",
    "        image_address = \"natural_images/z_fruit/fruit_00\" + str(i) + \".jpg\"\n",
    "    if(i <= 9 & i > 0):\n",
    "        image_address = \"natural_images/z_fruit/fruit_000\" + str(i) + \".jpg\"\n",
    "    image = Image.open(image_address)\n",
    "    my_image = np.array(image.resize((150, 150), Image.ANTIALIAS))\n",
    "    my_image = my_image.reshape(1,150,150,3)\n",
    "    train_x = np.append(train_x, my_image, axis = 0)\n",
    "    temp = np.array([7]).reshape(1,1)\n",
    "    train_y = np.append(train_y, temp, axis = 0)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "train_x_backup = train_x\n",
    "train_y_backup = train_y\n",
    "nb_classes = 8\n",
    "targets = train_y.reshape(-1)\n",
    "train_y = np.eye(nb_classes)[targets]\n",
    "print(train_y.shape)\n",
    "train_x = train_x/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 150, 150, 3)\n",
      "(20, 1)\n",
      "(40, 150, 150, 3)\n",
      "(40, 1)\n",
      "(60, 150, 150, 3)\n",
      "(60, 1)\n",
      "(80, 150, 150, 3)\n",
      "(80, 1)\n",
      "(100, 150, 150, 3)\n",
      "(100, 1)\n",
      "(120, 150, 150, 3)\n",
      "(120, 1)\n",
      "(140, 150, 150, 3)\n",
      "(140, 1)\n",
      "(160, 150, 150, 3)\n",
      "(160, 1)\n",
      "(160, 8)\n"
     ]
    }
   ],
   "source": [
    "# Prepare Test Data\n",
    "# CNN for car = 0, person = 1, dog = 2, airplane = 3 - 100 examples each for training\n",
    "# cat = 4, flower = 5, motorbike = 6, fruit = 7\n",
    "# training_x = (example,d,d,d), training_y = (example,d) -- > ofter one-hot encoding\n",
    "test_example = train_example + 10 + 20 # train_set size\n",
    "# Car ------------------------\n",
    "for i in range((train_example+10), test_example):\n",
    "    if(i <= 999 & i > 99):\n",
    "        image_address = \"natural_images/z_car/car_0\" + str(i) + \".jpg\"\n",
    "    if(i <= 99 & i > 9):\n",
    "        image_address = \"natural_images/z_car/car_00\" + str(i) + \".jpg\"\n",
    "    if(i <= 9 & i > 0):\n",
    "        image_address = \"natural_images/z_car/car_000\" + str(i) + \".jpg\"\n",
    "    image = Image.open(image_address)\n",
    "    my_image = np.array(image.resize((150, 150), Image.ANTIALIAS))\n",
    "    my_image = my_image.reshape(1,150,150,3)\n",
    "    if(i == (train_example+10)):\n",
    "        test_x = my_image\n",
    "        test_y = np.array([0]).reshape(1,1)\n",
    "    else:\n",
    "        test_x = np.append(test_x, my_image, axis = 0)\n",
    "        temp = np.array([0]).reshape(1,1)\n",
    "        test_y = np.append(test_y, temp, axis = 0)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "# person ----------------------\n",
    "for i in range((train_example+10), test_example):\n",
    "    if(i <= 999 & i > 99):\n",
    "        image_address = \"natural_images/z_person/person_0\" + str(i) + \".jpg\"\n",
    "    if(i <= 99 & i > 9):\n",
    "        image_address = \"natural_images/z_person/person_00\" + str(i) + \".jpg\"\n",
    "    if(i <= 9 & i > 0):\n",
    "        image_address = \"natural_images/z_person/person_000\" + str(i) + \".jpg\"\n",
    "    image = Image.open(image_address)\n",
    "    my_image = np.array(image.resize((150, 150), Image.ANTIALIAS))\n",
    "    my_image = my_image.reshape(1,150,150,3)\n",
    "\n",
    "    test_x = np.append(test_x, my_image, axis = 0)\n",
    "    temp = np.array([1]).reshape(1,1)\n",
    "    test_y = np.append(test_y, temp, axis = 0)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "# dog -------------------------\n",
    "for i in range((train_example+10), test_example):\n",
    "    if(i <= 999 & i > 99):\n",
    "        image_address = \"natural_images/z_dog/dog_0\" + str(i) + \".jpg\"\n",
    "    if(i <= 99 & i > 9):\n",
    "        image_address = \"natural_images/z_dog/dog_00\" + str(i) + \".jpg\"\n",
    "    if(i <= 9 & i > 0):\n",
    "        image_address = \"natural_images/z_dog/dog_000\" + str(i) + \".jpg\"\n",
    "    image = Image.open(image_address)\n",
    "    my_image = np.array(image.resize((150, 150), Image.ANTIALIAS))\n",
    "    my_image = my_image.reshape(1,150,150,3)\n",
    "\n",
    "    test_x = np.append(test_x, my_image, axis = 0)\n",
    "    temp = np.array([2]).reshape(1,1)\n",
    "    test_y = np.append(test_y, temp, axis = 0)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "# airplane ---------------------\n",
    "for i in range((train_example+10), test_example):\n",
    "    if(i <= 999 & i > 99):\n",
    "        image_address = \"natural_images/z_airplane/airplane_0\" + str(i) + \".jpg\"\n",
    "    if(i <= 99 & i > 9):\n",
    "        image_address = \"natural_images/z_airplane/airplane_00\" + str(i) + \".jpg\"\n",
    "    if(i <= 9 & i > 0):\n",
    "        image_address = \"natural_images/z_airplane/airplane_000\" + str(i) + \".jpg\"\n",
    "    image = Image.open(image_address)\n",
    "    my_image = np.array(image.resize((150, 150), Image.ANTIALIAS))\n",
    "    my_image = my_image.reshape(1,150,150,3)\n",
    "\n",
    "    test_x = np.append(test_x, my_image, axis = 0)\n",
    "    temp = np.array([3]).reshape(1,1)\n",
    "    test_y = np.append(test_y, temp, axis = 0)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "# cat -------------------------\n",
    "for i in range((train_example+10), test_example):\n",
    "    if(i <= 999 & i > 99):\n",
    "        image_address = \"natural_images/z_cat/cat_0\" + str(i) + \".jpg\"\n",
    "    if(i <= 99 & i > 9):\n",
    "        image_address = \"natural_images/z_cat/cat_00\" + str(i) + \".jpg\"\n",
    "    if(i <= 9 & i > 0):\n",
    "        image_address = \"natural_images/z_cat/cat_000\" + str(i) + \".jpg\"\n",
    "    image = Image.open(image_address)\n",
    "    my_image = np.array(image.resize((150, 150), Image.ANTIALIAS))\n",
    "    my_image = my_image.reshape(1,150,150,3)\n",
    "\n",
    "    test_x = np.append(test_x, my_image, axis = 0)\n",
    "    temp = np.array([4]).reshape(1,1)\n",
    "    test_y = np.append(test_y, temp, axis = 0)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "# flower -----------------------\n",
    "for i in range((train_example+10), test_example):\n",
    "    if(i <= 999 & i > 99):\n",
    "        image_address = \"natural_images/z_flower/flower_0\" + str(i) + \".jpg\"\n",
    "    if(i <= 99 & i > 9):\n",
    "        image_address = \"natural_images/z_flower/flower_00\" + str(i) + \".jpg\"\n",
    "    if(i <= 9 & i > 0):\n",
    "        image_address = \"natural_images/z_flower/flower_000\" + str(i) + \".jpg\"\n",
    "    image = Image.open(image_address)\n",
    "    my_image = np.array(image.resize((150, 150), Image.ANTIALIAS))\n",
    "    my_image = my_image.reshape(1,150,150,3)\n",
    "\n",
    "    test_x = np.append(test_x, my_image, axis = 0)\n",
    "    temp = np.array([5]).reshape(1,1)\n",
    "    test_y = np.append(test_y, temp, axis = 0)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "# motorbike --------------------\n",
    "for i in range((train_example+10), test_example):\n",
    "    if(i <= 999 & i > 99):\n",
    "        image_address = \"natural_images/z_motorbike/motorbike_0\" + str(i) + \".jpg\"\n",
    "    if(i <= 99 & i > 9):\n",
    "        image_address = \"natural_images/z_motorbike/motorbike_00\" + str(i) + \".jpg\"\n",
    "    if(i <= 9 & i > 0):\n",
    "        image_address = \"natural_images/z_motorbike/motorbike_000\" + str(i) + \".jpg\"\n",
    "    image = Image.open(image_address)\n",
    "    my_image = np.array(image.resize((150, 150), Image.ANTIALIAS))\n",
    "    my_image = my_image.reshape(1,150,150,3)\n",
    "\n",
    "    test_x = np.append(test_x, my_image, axis = 0)\n",
    "    temp = np.array([6]).reshape(1,1)\n",
    "    test_y = np.append(test_y, temp, axis = 0)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "# fruit -------------------------\n",
    "for i in range((train_example+10), test_example):\n",
    "    if(i <= 999 & i > 99):\n",
    "        image_address = \"natural_images/z_fruit/fruit_0\" + str(i) + \".jpg\"\n",
    "    if(i <= 99 & i > 9):\n",
    "        image_address = \"natural_images/z_fruit/fruit_00\" + str(i) + \".jpg\"\n",
    "    if(i <= 9 & i > 0):\n",
    "        image_address = \"natural_images/z_fruit/fruit_000\" + str(i) + \".jpg\"\n",
    "    image = Image.open(image_address)\n",
    "    my_image = np.array(image.resize((150, 150), Image.ANTIALIAS))\n",
    "    my_image = my_image.reshape(1,150,150,3)\n",
    "\n",
    "    test_x = np.append(test_x, my_image, axis = 0)\n",
    "    temp = np.array([7]).reshape(1,1)\n",
    "    test_y = np.append(test_y, temp, axis = 0)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "\n",
    "test_x_backup = test_x\n",
    "test_y_backup = test_y\n",
    "nb_classes = 8\n",
    "targets = test_y.reshape(-1)\n",
    "test_y = np.eye(nb_classes)[targets]\n",
    "print(test_y.shape)\n",
    "test_x = test_x/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "150\n",
      "3\n",
      "8\n",
      "Tensor(\"tf_x:0\", shape=(?, 150, 150, 3), dtype=float32)\n",
      "Tensor(\"tf_y:0\", shape=(?, 8), dtype=float32)\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "print(train_x.shape[1])\n",
    "print(train_x.shape[2])\n",
    "print(train_x.shape[3])\n",
    "print(train_y.shape[1])\n",
    "tf_x = tf.placeholder(tf.float32, shape=(None, train_x.shape[1], train_x.shape[2], train_x.shape[3]), name='tf_x')\n",
    "tf_y = tf.placeholder(tf.float32, shape=(None, train_y.shape[1]), name='tf_y')\n",
    "print(tf_x)\n",
    "print(tf_y)\n",
    "\n",
    "# weights -----------------\n",
    "# w1 - 8 filters\n",
    "# w2 - 16 filter\n",
    "#W1 = tf.get_variable('W1', shape=(4,4,3,8), initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "#W2 = tf.get_variable('W2', shape=(2,2,8,16), initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "W1 = tf.get_variable('W1', shape=(8,8,3,64), initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "W2 = tf.get_variable('W2', shape=(6,6,64,32), initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "W3 = tf.get_variable('W3', shape=(4,4,32,8), initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "W4 = tf.get_variable('W4', shape=(2,2,8,12), initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "\n",
    "parameters = {\"W1\": W1, \"W2\": W2, \"W3\" : W3, \"W4\" : W4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1299bea10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1299bea10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1299bea10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x1299bea10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1299ebbd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1299ebbd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1299ebbd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1299ebbd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "W1 = parameters['W1']\n",
    "W2 = parameters['W2']\n",
    "W3 = parameters['W3']\n",
    "W4 = parameters['W4']\n",
    "\n",
    "# Block - 1\n",
    "#stride of 1 and padding 'SAME'\n",
    "Z1 = tf.nn.conv2d(tf_x, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "# RELU - Activation\n",
    "A1 = tf.nn.relu(Z1)\n",
    "# window 8x8, stride 8, padding 'SAME'\n",
    "P1 = tf.nn.max_pool(A1, ksize=[1, 8, 8, 1], strides=[1, 8, 8, 1], padding='SAME')\n",
    "# Block - 2\n",
    "# stride 1, padding 'SAME'\n",
    "Z2 = tf.nn.conv2d(P1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "# RELU\n",
    "A2 = tf.nn.relu(Z2)\n",
    "# stride 4 and padding 'SAME'\n",
    "P2 = tf.nn.max_pool(A2, ksize=[1, 4, 4, 1], strides=[1, 4, 4, 1], padding='SAME')\n",
    "# Block - 3\n",
    "# stride 1, padding 'SAME'\n",
    "Z3 = tf.nn.conv2d(P2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "# RELU\n",
    "A3 = tf.nn.relu(Z3)\n",
    "# stride 2 and padding 'SAME'\n",
    "P3 = tf.nn.max_pool(A3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "# Block - 4\n",
    "# stride 1, padding 'SAME'\n",
    "Z4 = tf.nn.conv2d(P3, W4, strides=[1, 1, 1, 1], padding='SAME')\n",
    "# RELU\n",
    "A4 = tf.nn.relu(Z4)\n",
    "# stride 2 and padding 'SAME'\n",
    "P4 = tf.nn.max_pool(A4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# Fully Connected Block\n",
    "# FLATTEN \n",
    "P4 = tf.contrib.layers.flatten(P4)\n",
    "# FULLY-CONNECTED without non-linear activation function.\n",
    "# 8 node - 8 classes\n",
    "Z5 = tf.contrib.layers.fully_connected(P4, 8, activation_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'fully_connected/BiasAdd:0' shape=(?, 8) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z5, labels=tf_y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "\n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # shuffle\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:,:]\n",
    "    shuffled_Y = Y[permutation,:]\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 2.098513\n",
      "Cost after epoch 0: 4.175509\n",
      "Cost after epoch 1: 2.063156\n",
      "Cost after epoch 1: 4.116013\n",
      "Cost after epoch 2: 2.034703\n",
      "Cost after epoch 2: 4.053840\n",
      "Cost after epoch 3: 1.995170\n",
      "Cost after epoch 3: 3.968534\n",
      "Cost after epoch 4: 1.930002\n",
      "Cost after epoch 4: 3.808185\n",
      "Cost after epoch 5: 1.831729\n",
      "Cost after epoch 5: 3.604486\n",
      "Cost after epoch 6: 1.740165\n",
      "Cost after epoch 6: 3.352499\n",
      "Cost after epoch 7: 1.591813\n",
      "Cost after epoch 7: 3.077256\n",
      "Cost after epoch 8: 1.422932\n",
      "Cost after epoch 8: 2.725405\n",
      "Cost after epoch 9: 1.286301\n",
      "Cost after epoch 9: 2.398013\n",
      "Cost after epoch 10: 1.054461\n",
      "Cost after epoch 10: 2.037805\n",
      "Cost after epoch 11: 0.867701\n",
      "Cost after epoch 11: 1.701241\n",
      "Cost after epoch 12: 0.726506\n",
      "Cost after epoch 12: 1.405185\n",
      "Cost after epoch 13: 0.614856\n",
      "Cost after epoch 13: 1.166971\n",
      "Cost after epoch 14: 0.511846\n",
      "Cost after epoch 14: 0.982075\n",
      "Cost after epoch 15: 0.411688\n",
      "Cost after epoch 15: 0.836143\n",
      "Cost after epoch 16: 0.337391\n",
      "Cost after epoch 16: 0.719935\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "seed = 3\n",
    "(m, n_H0, n_W0, n_C0) = train_x.shape             \n",
    "n_y = train_y.shape[1]                            \n",
    "costs = []\n",
    "num_epochs = 20\n",
    "minibatch_size = 512\n",
    "print_cost = True\n",
    "\n",
    "# Initialize all the variables globally\n",
    "init = tf.global_variables_initializer()\n",
    "     \n",
    "# Start the session to compute the tensorflow graph\n",
    "with tf.Session() as sess:\n",
    "        \n",
    "    sess.run(init)\n",
    "        \n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        minibatch_cost = 0.\n",
    "        num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "        seed = seed + 1\n",
    "        minibatches = random_mini_batches(train_x, train_y, minibatch_size, seed)\n",
    "\n",
    "        for minibatch in minibatches:\n",
    "\n",
    "            # Select a minibatch\n",
    "            (minibatch_X, minibatch_Y) = minibatch\n",
    "            _ , temp_cost = sess.run([optimizer, cost], feed_dict={tf_x:minibatch_X, tf_y:minibatch_Y})\n",
    "    \n",
    "            minibatch_cost += temp_cost / num_minibatches\n",
    "                \n",
    "            if print_cost == True:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(minibatch_cost)\n",
    "        \n",
    "        \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(0.001))\n",
    "    plt.show()\n",
    "    # Calculate the correct predictions\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, 'natural_image_model') \n",
    "    predict_op = tf.argmax(Z5,1)\n",
    "    correct_prediction = tf.equal(predict_op, tf.argmax(tf_y,1))\n",
    "    \n",
    "    # Calculate accuracy on the test set\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"Accuracy:\")\n",
    "    train_accuracy = accuracy.eval({tf_x: train_x, tf_y: train_y})\n",
    "    print(\"Train Accuracy:\", train_accuracy)\n",
    "    test_accuracy = accuracy.eval({tf_x: test_x, tf_y: test_y})\n",
    "    print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the weights\n",
    "saver = tf.train.import_meta_graph('natural_image_model.meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
